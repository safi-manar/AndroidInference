import argparse
import os
import csv
import json

from pprint import pprint

from preprocessor import Preprocessor
import pandas

def parse_args():
    """Specify a parser for a single mandatory command-line argument"""
    parser = argparse.ArgumentParser(description='Preprocessing operations for CSVs generated by data-extract.py')
    parser.add_argument('extract_path', help='path to a single device\'s extracted data')
    parser.add_argument('-o', '--out-path', help='path to the output directory, defaults to in-place preprocessing if left unspecified')
    parser.add_argument('-s', '--spec-file', help='path to a custom preprocessing spec file')

    return parser.parse_args()

def read_spec(spec_file):
    """Reads the data in the spec JSON file"""
    print 'spec_file=%s' % spec_file
    with open(spec_file) as json_file:
        json_data = json.load(json_file)

        return json_data

# Read arguments
script_path = os.path.dirname(os.path.realpath(__file__))
default_spec_file = os.path.join(script_path, 'spec.json')
cols_key = 'primary-cols'
rename_key = 'rename'

args = parse_args()
extract_path = args.extract_path
out_path = os.path.abspath(args.out_path) if args.out_path is not None else extract_path
spec_file = args.spec_file if args.spec_file is not None else default_spec_file

print 'extract_path="%s"' % extract_path
print 'out_path="%s"' % out_path

if(not os.path.isdir(out_path)):
    os.makedirs(out_path)

# Read spec
spec = read_spec(spec_file)
target_files = [val for val in spec.keys() if val.endswith('.csv')]
sensor_keys = spec['meta']['sensormerge'].split(',')
all_keys = spec['meta']['allmerge'].split(',')

# Preprocess extracted data
extracted_files = [f for f in os.listdir(extract_path) if os.path.isfile(os.path.join(extract_path, f))]
to_preprocess = [f for f in extracted_files if f in target_files]
to_ignore = [f for f in extracted_files if f not in target_files]

sensormerge = []
othermerge = []
for target in to_preprocess:
    target_path = os.path.join(extract_path, target)
    columns = spec[target][cols_key].split(',')
    renames = spec[target][rename_key] if rename_key in spec[target].keys() else None

    pp = Preprocessor(target_path, columns, renames)

    preproced = pp.run(out_path)
    if set(sensor_keys) < set(columns):
        sensormerge.append(preproced)
    else:
        othermerge.append(preproced)

# Merge sensors together first, then everything else, then write it out
merged = reduce(lambda x,y: x.merge(y, how='outer', on=sensor_keys, sort=False), sensormerge)
merged = reduce(lambda x,y: x.merge(y, how='outer', on=all_keys, sort=True), othermerge, merged)
merged.to_csv(os.path.join(out_path, 'merged.csv'), header=merged.columns, index=False)

for ignore in to_ignore:
    print 'Ignored %s' % ignore
